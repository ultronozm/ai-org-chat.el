#+title: ai-org-chat.el: Threaded chat with AI agent
#+author: Paul Nelson

* Overview
This package supports a threaded AI chat inside any org-mode buffer.  Here's what it looks like:

#+attr_html: :width 800px
#+attr_latex: :width 800px
[[./img/fruits.png]]

The design is inspired by the ChatGPT web interface.  There are [[https://www.reddit.com/r/emacs/comments/14glmqc/use_emacs_as_a_chatgpt_app/][many AI chat packages]] for Emacs, but I am not aware of any that naturally support multiple conversational pathways.  (Update: [[https://github.com/karthink/gptel][gptel]] now has a similar feature, which I haven't yet tried; it depends upon an pre-release version of Org.)  I'm also using this package as a way to experiment with ways to tighten the editing loop with AI in Emacs, via context, diffs, etc.

The package comes with one main function, =ai-org-chat-respond=, that operates in any org-mode buffer.  It extracts a conversation history from the parent entries, treating an entry as belonging to the AI if its heading is "AI" and otherwise to the user.  This conversation history is passed along to the OpenAI library to generate a response.

The "plumbing" concerning API calls is outsourced by default to the [[https://github.com/karthink/gptel][gptel]] library, which requires the user to provide an OpenAI API key.  By customizing the variable =ai-org-chat-request-fn=, any other backend could be used.

[[https://www.gnu.org/software/emacs/manual/html_node/emacs/Narrowing.html][Narrowing]] provides a simple way to truncate the conversation history if it becomes too long -- only the restricted part of the buffer is considered.

(TODO: document these next features better.)

A "system message" (at least for OpenAI/Anthropic models; I haven't checked more generally) can be specified via the customization variable =ai-org-chat-system-message=.  "Context" can be passed along with the system message to share the contents of files or Emacs buffers with the AI (see [[Context]]).

There is some support for quickly launching Ediff sessions that compare modifications suggested by the AI to their sources (see [[Usage]]).

* Configuration
This package depends (by default) upon [[https://github.com/karthink/gptel][gptel]], so you should first set that up and configure it.  The following configuration works for me on MacOS after setting the environment variable "OPENAI_API_KEY" to my API key.

#+begin_src elisp
(use-package exec-path-from-shell
  :ensure
  :init
  (exec-path-from-shell-initialize))
  
(use-package gptel
  :ensure
  :after exec-path-from-shell
  :config
  (setq gptel-api-key (exec-path-from-shell-getenv "OPENAI_API_KEY")))
#+end_src

Next, download this repository, install using =M-x package-install-file= (or package-vc-install, straight, elpaca, ...), and add =(use-package ai-org-chat)= to your [[https://www.emacswiki.org/emacs/InitFile][init file]].  For a slightly more elaborate configuration, use something like the following:

#+begin_src elisp
(use-package ai-org-chat
  :bind
  (:map global-map
        ("C-c /" . ai-org-chat-new))
  (:map ai-org-chat-minor-mode-map
        ("C-c <return>" . ai-org-chat-respond)
        ("C-c n" . ai-org-chat-branch)
        ("C-c e" . ai-org-chat-compare)
        ("C-c x" . ai-org-chat-set-context-style)
        ("C-c a b" . ai-org-chat-add-buffer-context)
        ("C-c a f" . ai-org-chat-add-file-context)
        ("C-c a p" . ai-org-chat-add-project-files-context))
  :commands (ai-org-chat-setup-buffer)
  :custom
  (ai-org-chat-user-name "Paul")
  (ai-org-chat-dir "~/gpt")
  (ai-org-chat-context-style 'visible-buffers))
#+end_src

* Usage
When you want to ask the AI something, do =M-x ai-org-chat-new= (or =C-c /=, if you followed the above configuration).  This visits a new file in the specified directory ("~/gpt" by default).  If the region was active, then it will be quoted in the new buffer.  Example:

#+attr_html: :width 800px
#+attr_latex: :width 800px
[[./img/animated.gif]]

The org-mode buffer has =ai-org-chat-minor-mode= activated, whose only purpose is to support user-defined keybindings like in the above =use-package= declaration.  If you want to work in some other org file, you can either activate this minor mode manually or do =M-x ai-org-chat-setup-buffer=.

There are a few useful commands:

- =ai-org-chat-respond= (=C-c <return>=) :: This is the main function, which tells the AI to generate a new response to the conversation node at point.  It works in /any/ org-mode buffer, not just ones created via =ai-org-chat-new=.
- =ai-org-chat-branch= (=C-c n=) :: This is a convenience function that creates a new conversation branch at point.
- =ai-org-chat-compare= (=C-c e=) :: This launches an Ediff session, in a temporary tab, comparing the org-mode block at point with the contents of some other visible buffer (selected via ace-window in case there are multiple other buffers).  This is useful for studying and implementing changes suggested by the AI.
- =ai-org-chat-convert-markdown-blocks-to-org= :: LLM's often return code in markdown format (even when you instruct them otherwise).  This function converts all markdown code blocks in the buffer to org-mode code blocks.

There are also a few commands concerning context (see [[Context]] below).
- =ai-org-chat-set-context-style= (=C-c c=) :: This sets =ai-org-chat-context-style=.
- =ai-org-chat-add-buffer-context= (=C-c a b=) :: This adds buffers as context to the node at point.
- =ai-org-chat-add-buffer-context= (=C-c a f=) :: This adds files as context to the node at point.
- =ai-org-chat-add-project-context= (=C-c a p=) :: This adds the contents of a project as context to the node at point.

* Context
The buffer-local customization variable =ai-org-chat-context-style= can currently attain three values: nil, =visible-contents= and =visible-buffers=.  You can adjust its default value by tweaking the above =use-package= form.  When it is non-nil, the system message is appended with some of the contents of the visible buffers.  The contents are:
- for =visible-contents=, the visible content of all visible buffers.
- for =visible-buffers=, the complete content of all visible buffers.

This makes the chat client behave a bit like a pair-programmer, seeing what you see and responding to changes you make.  It pairs well with the =ai-org-chat-compare= feature, which

The commands =ai-org-chat-add-buffer-context= and =ai-org-chat-add-file-context= add "permanent" context, independent of which windows are visible, to the current node.  The context is specified by a list of files or buffers, contained in the :CONTEXT: property of the node.  Child nodes inherit the context of their parent nodes.  You can use a top-level property drawer to set context for an entire file.  The convenience function =ai-org-chat-add-project-context= adds all the files in a project to the context.
